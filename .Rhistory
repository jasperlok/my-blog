#filter(lambda == 0.12152)
cv_glmnet_0.1 %>%
tidy() %>%
filter(round(lambda, 5) == 0.12152)
View(cv_glmnet_0.1)
deviance(cv_glmnet_0.1)
print(cv_glmnet_0.1)
plot(cv_glmnet_0.1)
assess.glmnet(cv_glmnet_0.1, newx = newx, newy = df_test$clm.count)
assess.glmnet(cv_glmnet_0.1, newx = newx, newy = df_test$clm.count, offset = log(df_test$exposure))
assess.glmnet(cv_glmnet_0.1, newx = newx, newy = df_test$clm.count, new_offset = log(df_test$exposure))
assess.glmnet(cv_glmnet_0.1, newx = newx, newy = df_test$clm.count, newoffset = log(df_test$exposure))
assess.glmnet(cv_glmnet_0.1, newx = newx, newy = df_test$clm.count, newoffset = log(df_test$exposure))$deviance
cv_glmnet_0.1
deviance.glmnet(cv_glmnet_0.1)
deviance(cv_glmnet_0.1)
View(cv_glmnet_0.1)
deviance(cv_glmnet_0.1$glmnet.fit)
deviance(glmnet_model)
summary(glmnet_model)
glmnet_model$dev.ratio
deviance(cv_glmnet_0.1$glmnet.fit$dev.ratio)
deviance(cv_glmnet_0.1$glmnet.fit[dev.ratio])
deviance(cv_glmnet_0.1$glmnet.fit['dev.ratio'])
deviance(cv_glmnet_0.1$glmnet.fit)
cv_glmnet_0.1$glmnet.fit
cv_glmnet_0.1$glmnet.fit[71]
cv_glmnet_0.1$glmnet.fit
cv_glmnet_0.1$glmnet.fit[[71]]
cv_glmnet_0.1$glmnet.fit[71]
cv_glmnet_0.1$glmnet.fit
type(cv_glmnet_0.1$glmnet.fit)
typeof(cv_glmnet_0.1$glmnet.fit)
cv_glmnet_0.1$glmnet.fit[71]
cv_glmnet_0.1$glmnet.fit
cv_glmnet_0.1$glmnet.fit %>%
as.data.frame()
as.data.frame(cv_glmnet_0.1$glmnet.fit)
cv_glmnet_0.1$glmnet.fit %>%
tidy()'
cv_glmnet_0.1$glmnet.fit %>%
tidy()
tidy(cv_glmnet_0.1$glmnet.fit)
tidy(cv_glmnet_0.1$glmnet.fit) %>%
filter(71)
tidy(cv_glmnet_0.1$glmnet.fit) %>%
filter(index == 71)
tidy(cv_glmnet_0.1$glmnet.fit)
tidy(cv_glmnet_0.1$glmnet.fit) %>%
filter(step == 71)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/tiles.jpg")
knitr::include_graphics("image/journey.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet', 'glue')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::include_graphics("image/nice car.jpg")
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df_num <- df %>%
select_if(is.numeric)
corrplot(cor(df_num, use="pairwise.complete.obs"),
method = "number",
type = "upper",
tl.cex = 0.65,
number.cex = 0.65,
diag = FALSE)
df_1 <- df %>%
select(-c(year, drv.age, veh.age, clm.incurred))
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() %>%
bake(df_1)
df_split <- initial_split(df_recoded, prop = 0.6, strata = clm.count)
df_train <- training(df_split)
df_test <- testing(df_split)
# predictors need to be in matrix format
x <- df_train %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
y <- df_train$clm.count
newx <- df_test %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
glmnet_model <- glmnet(x,
y,
family = "poisson",
offset = log(df_train$exposure))
glmnet_model %>% tidy()
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/tiles.jpg")
knitr::include_graphics("image/journey.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet', 'glue')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::include_graphics("image/nice car.jpg")
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df_num <- df %>%
select_if(is.numeric)
corrplot(cor(df_num, use="pairwise.complete.obs"),
method = "number",
type = "upper",
tl.cex = 0.65,
number.cex = 0.65,
diag = FALSE)
df_1 <- df %>%
select(-c(year, drv.age, veh.age, clm.incurred))
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() %>%
bake(df_1)
df_split <- initial_split(df_recoded, prop = 0.6, strata = clm.count)
df_train <- training(df_split)
df_test <- testing(df_split)
# predictors need to be in matrix format
x <- df_train %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
y <- df_train$clm.count
newx <- df_test %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
glmnet_model <- glmnet(x,
y,
family = "poisson",
offset = log(df_train$exposure))
glmnet_model %>% tidy()
glmnet_model$dev.ratio
alpha_list <- c(0, 0.25, 0.5, 0.75, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(get(glue("cv_glmnet_", i)))
}
coef(cv_glmnet_0.25)
coef(cv_glmnet_0.25, s = "lambda.min")
coef(cv_glmnet_0.25) %>%
as.matrix()
ggplot(df, aes(x = factor(clm.count), y = log(height))) +
geom_violin(draw_quantiles = c(0.5))
ggplot(df, aes(prior.claims)) +
geom_histogram(aes(group = clm.count, fill = clm.count, alpha = 0.15)) #+
#facet_wrap(~clm.count)
cv_glmnet_0.25 %>%
tidy() %>%
filter(round(lambda, 5) == 0.12152)
tidy(cv_glmnet_0.1$glmnet.fit) %>%
filter(step == 71)
cv_glmnet_tidy <- tidy(cv_glmnet_0.25)
cv_glmnet_tidy
glance(glmnet_model)
glmnet_predict <- predict(glmnet_model,
type = "response",
newx = newx,
newoffset = log(df_test$exposure))
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet_tf <- cv_predict_glmnet %>%
as_tibble() %>%
setNames(c("prediction")) %>%
bind_cols(df_test)
cv_predict_glmnet_tf
glance(cv_glmnet)
glance(cv_glmnet_0.25)
View(df_1)
View(df_1)
View(df_test)
tidy(cv_glmnet_0.25$glmnet.fit) %>%
filter(step == 71)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/tiles.jpg")
knitr::include_graphics("image/journey.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet', 'glue')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::include_graphics("image/nice car.jpg")
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df_num <- df %>%
select_if(is.numeric)
corrplot(cor(df_num, use="pairwise.complete.obs"),
method = "number",
type = "upper",
tl.cex = 0.65,
number.cex = 0.65,
diag = FALSE)
df_1 <- df %>%
select(-c(year, drv.age, veh.age, clm.incurred))
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() %>%
bake(df_1)
df_split <- initial_split(df_recoded, prop = 0.6, strata = clm.count)
df_train <- training(df_split)
df_test <- testing(df_split)
# predictors need to be in matrix format
x <- df_train %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
y <- df_train$clm.count
newx <- df_test %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
glmnet_model <- glmnet(x,
y,
family = "poisson",
offset = log(df_train$exposure))
glmnet_model %>%
tidy()
glmnet_model$dev.ratio
alpha_list <- c(0, 0.25, 0.5, 0.75, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(get(glue("cv_glmnet_", i)))
}
cv_glmnet_0 %>%
tidy()
glmnet_model$s
glmnet_model$lamda
glmnet_model$lamda.min
glance(glmnet_fit)
glance(glmnet_model)
alpha_list <- c(0, 0.25, 0.5, 0.75, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(glue("cv_glmnet_", i))
print(get(glue("cv_glmnet_", i)))
}
coef(cv_glmnet_1)
coef(cv_glmnet_0.25)
coef(cv_glmnet_0.25, s = "lambda.min")
tidy(cv_glmnet_0.25$glmnet.fit) %>%
filter(step == 75)
tidy(cv_glmnet_0.25$glmnet.fit) %>%
filter(step == 75)
tidy(cv_glmnet_0$glmnet.fit) %>%
filter(step == 75)
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet %>% tibble()
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet %>% as_tibble()
cv_predict_glmnet_tf <- cv_predict_glmnet %>%
as_tibble() %>%
setNames(c("prediction")) %>%
bind_cols(df_test)
cv_predict_glmnet_tf
cv_predict_glmnet_tf <- cv_predict_glmnet %>%
as_tibble() %>%
setNames(c("prediction")) %>%
bind_cols(df_test) %>%
select(c(prediction, clm.count))
cv_predict_glmnet_tf
View(cv_predict_glmnet_tf)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
plot(df$BUS_TOP_N)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/map.jpg")
distribution_df <- tibble('Types of Distributions' = c("Random",
"Uniform",
"Clustered"),
Descriptions = c("Any point is equally likely to occur at any location and the position of any point is not affected by the position of any other point",
"Every point is as far from all of its neighbors as possible",
"Many points are concentrated close together, and large areas that contain very few, if any, points"))
distribution_df %>%
kbl() %>%
kable_paper("hover", full_width = F, html_font = "Cambria", font_size = 15)
knitr::include_graphics("image/singapore.jpg")
knitr::include_graphics("image/DataMall_BusStop.png")
packages = c('sf', 'maptools', 'spatstat', 'tmap')
for (p in packages){
if(!require(p, character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
df <- st_read(dsn = "data/BusStopLocation", layer = "BusStop")
mpsz <- st_read(dsn = "data/SG Map", layer = "MP14_SUBZONE_WEB_PL")
st_crs(df)
st_crs(mpsz)
plot(df$BUS_TOP_N)
plot(df)
plot(df@BUS_TOP_N)
plot(df$BUS_TOP_N)
tmap_mode('plot')
tmap_mode('plot')
tm_shape(df) +
tm_dots()
tmap_mode('view')
tm_shape(df) +
tm_dots()
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="100%")
library(captioner)
knitr::include_graphics("image/lime.jpg")
knitr::include_graphics("image/lime.png")
knitr::include_graphics("image/sour.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'DALEXtra', 'themis',
'lime')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
df <- read_csv("https://raw.githubusercontent.com/jasperlok/my-blog/master/_posts/2022-03-12-marketbasket/data/general_data.csv")
set.seed(1234)
df_split <- initial_split(df,
prop = 0.6,
strata = Attrition)
df_train <- training(df_split)
df_test <- testing(df_split)
ranger_recipe <-
recipe(formula = Attrition ~ .,
data = df_train) %>%
step_impute_mean(NumCompaniesWorked,
TotalWorkingYears) %>%
step_nzv(all_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_upsample(Attrition)
ranger_spec <-
rand_forest(trees = 1000) %>%
set_mode("classification") %>%
set_engine("ranger")
ranger_workflow <-
workflow() %>%
add_recipe(ranger_recipe) %>%
add_model(ranger_spec)
ranger_fit <- ranger_workflow %>%
fit(data = df_train)
ranger_explainer <- explain_tidymodels(ranger_fit,
data = select(df_train, -Attrition),
y = df_train$Attrition,
verbose = FALSE)
model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer
top_3_obs <- predict(ranger_fit,
df_test,
type = "prob") %>%
bind_cols(df_test) %>%
arrange(desc(.pred_Yes)) %>%
slice_head(n = 3)
top_3_obs
top_3_obs <- top_3_obs %>%
select(-c(.pred_No, .pred_Yes))
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs %>%
select(-Attrition),
n_features = 8,
type = "lime")
plot(lime_rf_top_3 %>% filter(case == 1)) +
labs(title = "Before Modification")
plot(lime_rf_top_3 %>% filter(case == 1)) +
scale_fill_manual(values = alpha(c("grey", "black"), 0.6)) +
labs(title = "After Modification")
for (i in 1:3){
print(
plot(lime_rf_top_3 %>% filter(case == i))
)
}
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs %>%
select(-Attrition),
n_features = 8,
dist_fun = "manhattan",
kernel_width = 2,
type = "lime")
for (i in 1:3){
print(
plot(lime_rf_top_3 %>% filter(case == i))
)
}
plot_explanations(lime_rf_top_3)
knitr::include_graphics("image/lime_water.jpg")
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs, #%>%
#select(-Attrition),
n_features = 8,
type = "lime")
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs %>%
select(-Attrition),
n_features = 8,
type = "lime")
plot(lime_rf_top_3 %>% filter(case == 2)) +
labs(title = "Before Modification")
plot(lime_rf_top_3 %>% filter(case == 2)) +
scale_fill_manual(values = alpha(c("grey", "black"), 0.6)) +
labs(title = "After Modification")
warning()
warnings()
