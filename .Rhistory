tidy(cv_glmnet_0.25$glmnet.fit) %>%
filter(step == 71)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/tiles.jpg")
knitr::include_graphics("image/journey.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet', 'glue')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::include_graphics("image/nice car.jpg")
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df_num <- df %>%
select_if(is.numeric)
corrplot(cor(df_num, use="pairwise.complete.obs"),
method = "number",
type = "upper",
tl.cex = 0.65,
number.cex = 0.65,
diag = FALSE)
df_1 <- df %>%
select(-c(year, drv.age, veh.age, clm.incurred))
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() %>%
bake(df_1)
df_split <- initial_split(df_recoded, prop = 0.6, strata = clm.count)
df_train <- training(df_split)
df_test <- testing(df_split)
# predictors need to be in matrix format
x <- df_train %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
y <- df_train$clm.count
newx <- df_test %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
glmnet_model <- glmnet(x,
y,
family = "poisson",
offset = log(df_train$exposure))
glmnet_model %>%
tidy()
glmnet_model$dev.ratio
alpha_list <- c(0, 0.25, 0.5, 0.75, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(get(glue("cv_glmnet_", i)))
}
cv_glmnet_0 %>%
tidy()
glmnet_model$s
glmnet_model$lamda
glmnet_model$lamda.min
glance(glmnet_fit)
glance(glmnet_model)
alpha_list <- c(0, 0.25, 0.5, 0.75, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(glue("cv_glmnet_", i))
print(get(glue("cv_glmnet_", i)))
}
coef(cv_glmnet_1)
coef(cv_glmnet_0.25)
coef(cv_glmnet_0.25, s = "lambda.min")
tidy(cv_glmnet_0.25$glmnet.fit) %>%
filter(step == 75)
tidy(cv_glmnet_0.25$glmnet.fit) %>%
filter(step == 75)
tidy(cv_glmnet_0$glmnet.fit) %>%
filter(step == 75)
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet %>% tibble()
cv_predict_glmnet <- predict(cv_glmnet_0.25, newx = newx, newoffset = log(df_test$exposure), type = "response")
cv_predict_glmnet %>% as_tibble()
cv_predict_glmnet_tf <- cv_predict_glmnet %>%
as_tibble() %>%
setNames(c("prediction")) %>%
bind_cols(df_test)
cv_predict_glmnet_tf
cv_predict_glmnet_tf <- cv_predict_glmnet %>%
as_tibble() %>%
setNames(c("prediction")) %>%
bind_cols(df_test) %>%
select(c(prediction, clm.count))
cv_predict_glmnet_tf
View(cv_predict_glmnet_tf)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
plot(df$BUS_TOP_N)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/map.jpg")
distribution_df <- tibble('Types of Distributions' = c("Random",
"Uniform",
"Clustered"),
Descriptions = c("Any point is equally likely to occur at any location and the position of any point is not affected by the position of any other point",
"Every point is as far from all of its neighbors as possible",
"Many points are concentrated close together, and large areas that contain very few, if any, points"))
distribution_df %>%
kbl() %>%
kable_paper("hover", full_width = F, html_font = "Cambria", font_size = 15)
knitr::include_graphics("image/singapore.jpg")
knitr::include_graphics("image/DataMall_BusStop.png")
packages = c('sf', 'maptools', 'spatstat', 'tmap')
for (p in packages){
if(!require(p, character.only = T)){
install.packages(p)
}
library(p,character.only = T)
}
df <- st_read(dsn = "data/BusStopLocation", layer = "BusStop")
mpsz <- st_read(dsn = "data/SG Map", layer = "MP14_SUBZONE_WEB_PL")
st_crs(df)
st_crs(mpsz)
plot(df$BUS_TOP_N)
plot(df)
plot(df@BUS_TOP_N)
plot(df$BUS_TOP_N)
tmap_mode('plot')
tmap_mode('plot')
tm_shape(df) +
tm_dots()
tmap_mode('view')
tm_shape(df) +
tm_dots()
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="100%")
library(captioner)
knitr::include_graphics("image/lime.jpg")
knitr::include_graphics("image/lime.png")
knitr::include_graphics("image/sour.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'DALEXtra', 'themis',
'lime')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
df <- read_csv("https://raw.githubusercontent.com/jasperlok/my-blog/master/_posts/2022-03-12-marketbasket/data/general_data.csv")
set.seed(1234)
df_split <- initial_split(df,
prop = 0.6,
strata = Attrition)
df_train <- training(df_split)
df_test <- testing(df_split)
ranger_recipe <-
recipe(formula = Attrition ~ .,
data = df_train) %>%
step_impute_mean(NumCompaniesWorked,
TotalWorkingYears) %>%
step_nzv(all_predictors()) %>%
step_dummy(all_nominal_predictors()) %>%
step_upsample(Attrition)
ranger_spec <-
rand_forest(trees = 1000) %>%
set_mode("classification") %>%
set_engine("ranger")
ranger_workflow <-
workflow() %>%
add_recipe(ranger_recipe) %>%
add_model(ranger_spec)
ranger_fit <- ranger_workflow %>%
fit(data = df_train)
ranger_explainer <- explain_tidymodels(ranger_fit,
data = select(df_train, -Attrition),
y = df_train$Attrition,
verbose = FALSE)
model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer
top_3_obs <- predict(ranger_fit,
df_test,
type = "prob") %>%
bind_cols(df_test) %>%
arrange(desc(.pred_Yes)) %>%
slice_head(n = 3)
top_3_obs
top_3_obs <- top_3_obs %>%
select(-c(.pred_No, .pred_Yes))
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs %>%
select(-Attrition),
n_features = 8,
type = "lime")
plot(lime_rf_top_3 %>% filter(case == 1)) +
labs(title = "Before Modification")
plot(lime_rf_top_3 %>% filter(case == 1)) +
scale_fill_manual(values = alpha(c("grey", "black"), 0.6)) +
labs(title = "After Modification")
for (i in 1:3){
print(
plot(lime_rf_top_3 %>% filter(case == i))
)
}
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs %>%
select(-Attrition),
n_features = 8,
dist_fun = "manhattan",
kernel_width = 2,
type = "lime")
for (i in 1:3){
print(
plot(lime_rf_top_3 %>% filter(case == i))
)
}
plot_explanations(lime_rf_top_3)
knitr::include_graphics("image/lime_water.jpg")
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs, #%>%
#select(-Attrition),
n_features = 8,
type = "lime")
lime_rf_top_3 <- predict_surrogate(explainer = ranger_explainer,
new_observation = top_3_obs %>%
select(-Attrition),
n_features = 8,
type = "lime")
plot(lime_rf_top_3 %>% filter(case == 2)) +
labs(title = "Before Modification")
plot(lime_rf_top_3 %>% filter(case == 2)) +
scale_fill_manual(values = alpha(c("grey", "black"), 0.6)) +
labs(title = "After Modification")
warning()
warnings()
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="100%")
library(captioner)
knitr::include_graphics("image/lime.jpg")
getwd()
knitr::include_graphics("my-blog/_posts/2022-04-16-lime/image/lime.jpg")
knitr::include_graphics("_posts/2022-04-16-lime/image/lime.jpg")
unlink("_posts/2022-04-16-lime/lime_cache", recursive = TRUE)
knitr::include_graphics("lime_water.jpg")
knitr::include_graphics("_posts/2022-04-10-lime/image/lime_water.jpg")
knitr::include_graphics("image/lime_water.jpg")
install.packages("cli")
install.packages("cli")
options(htmltools.dir.version = FALSE)
pacman::p_load(captioner, knitr, kableExtra, tidyverse)
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="100%")
library(captioner)
pacman::p_load(tidyverse, readr, tidymodels, janitor, DALEXtra, fairmodels)
options(htmltools.dir.version = FALSE)
pacman::p_load(captioner, knitr, kableExtra, tidyverse)
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="100%")
library(captioner)
knitr::include_graphics("image/honest.jpg")
knitr::include_graphics("image/fair cream.jpg")
knitr::include_graphics("image/ML_fairness.png")
fairness_df <- tibble(`Fairness Measurement` = c("Accuracy equality ratio",
"Equal opportunity ratio",
"Predictive equality ratio",
"Predictive parity ratio",
"Statistical parity ratio"),
Measures = c("Both protected and unprotected groups have equal prediction accuracy",
"The protected and unprotected groups have same false negative rate",
"Both protected and unprotected groups have same false positive rate",
"Both protected and unprotected groups have the same precisions",
"Both protected and unprotected groups have the same probabilities to be assigned to positive predicted class"),
Remarks = c("",
"A.k.a. 'false negative error rate balance'",
"A.k.a. 'false positive error rate balance'",
"A.k.a. 'outcome test'",
"A.k.a. 'demographic parity, acceptance rate parity and benchmarking'"))
fairness_df %>%
kbl() %>%
kable_paper("hover", full_width = F, html_font = "Cambria", font_size = 15)
pacman::p_load(tidyverse, readr, tidymodels, janitor, DALEXtra, fairmodels)
df_org <- read_csv("data/train.csv")
set.seed(1234)
# point to the right explainer
model_type.dalex_explainer <- DALEXtra::model_type.dalex_explainer
predict_model.dalex_explainer <- DALEXtra::predict_model.dalex_explainer
df <- df_org %>%
clean_names() %>%
mutate(transported = as_factor(transported),
cryo_sleep = as_factor(cryo_sleep),
vip = as_factor(vip)) %>%
drop_na() %>%
mutate(cabin_deck = str_sub(cabin, 1, 1),
cabin_num = str_sub(cabin, 3, 3),
cabin_side = str_sub(cabin, -1, -1)) %>%
select(-c(passenger_id, name, cabin))
# model recipe
ranger_recipe <- recipe(formula = transported ~ .,
data = df) %>%
step_dummy(all_nominal_predictors())
# model specification
ranger_spec <-
rand_forest(trees = 1000) %>%
set_mode("classification") %>%
set_engine("ranger")
# model workflow
ranger_workflow <-
workflow() %>%
add_recipe(ranger_recipe) %>%
add_model(ranger_spec)
# fitting the model
ranger_fit <- ranger_workflow %>%
fit(data = df)
y_numeric <- df %>%
mutate(transported_numeric = case_when(transported == TRUE ~ 1,
TRUE ~ 0)) %>%
select(transported_numeric)
ranger_explainer <- explain_tidymodels(ranger_fit,
data = select(df, -transported),
y = y_numeric,
label = "randomForest",
verbose = FALSE)
protected_var <- df$home_planet
privileged_subgrp <- "Earth"
ranger_fair <- fairness_check(ranger_explainer,
protected = protected_var,
privileged = privileged_subgrp,
colorize = TRUE)
ranger_fair$parity_loss_metric_data
plot(ranger_fair)
metric_scores(ranger_fair, fairness_metrics = c("FPR"))$metric_scores_data %>%
ggplot(aes(x = subgroup, y = score)) +
geom_col() +
theme_minimal() +
labs(title = "False Positive Rate under Each Subgroup of Home Planet")
ranger_fair_0.6 <- fairness_check(ranger_explainer,
protected = protected_var,
privileged = privileged_subgrp,
epsilon = 0.6,
colorize = FALSE)
plot(ranger_fair_0.6)
# model recipe
xgboost_recipe <-
recipe(formula = transported ~ .,
data = df) %>%
step_dummy(all_nominal_predictors())
# model specification
xgboost_spec <-
boost_tree() %>%
set_mode("classification") %>%
set_engine("xgboost")
# model workflow
xgboost_workflow <-
workflow() %>%
add_recipe(xgboost_recipe) %>%
add_model(xgboost_spec)
# fitting the model
xgboost_fit <- xgboost_workflow %>%
fit(data = df)
# create explainer
xgboost_explainer <- explain_tidymodels(xgboost_fit,
data = select(df, -transported),
y = y_numeric,
label = "xgboost",
verbose = FALSE)
# model recipe
logit_recipe <-
recipe(formula = transported ~ .,
data = df) %>%
step_dummy(all_nominal_predictors())
# model specification
logit_spec <-
logistic_reg(penalty = 0.1) %>%
set_mode("classification") %>%
set_engine("glmnet")
# model workflow
logit_workflow <-
workflow() %>%
add_recipe(logit_recipe) %>%
add_model(logit_spec)
# fitting the model
logit_fit <- logit_workflow %>%
fit(data = df)
# create explainer
logit_explainer <- explain_tidymodels(logit_fit,
data = select(df, -transported),
y = y_numeric,
label = "logistic",
verbose = FALSE)
all_fair <- fairness_check(ranger_explainer,
xgboost_explainer,
logit_explainer,
protected = protected_var,
privileged = privileged_subgrp,
colorize = FALSE)
plot(all_fair)
plot(fairness_radar(all_fair))
plot(performance_and_fairness(all_fair, fairness_metric = "STP"))
knitr::include_graphics("image/hands.jpg")
library(cronologia)
jasper_df <- data.frame(
event = c("Data Scientist",
"Master of IT in Business",
"Actuarial Life Pricing Assistant Manager, Life Reporting Assistant Manager & Data Analytics Manager",
"Actuarial Pricing Senior Executive",
"Actuarial Pricing Senior Executive",
"Bachelor of Actuarial Studies"),
desc = c("Partner Re",
"Singapore Management University",
"NTUC Income Insurance Co-operative Limited",
"Great Eastern Life Assurance Co Ltd",
"Prudential Assurance Company Singapore",
"The Australian National University"),
desc_2 = c("Aug 2022 - Present",
"Jul 2022",
"Jul 2015 - Jul 2022",
"Oct 2014 - Jun 2014",
"Mar 2012 - Oct 2014",
"Dec 2019"))
create_tml_2(df = jasper_df,
smr = "event",
dsc = "desc",
dsc_size = "16px",
dsc2 = "desc_2",
open = TRUE)
library(pacman)
knitr::include_graphics("image/books.jpg")
