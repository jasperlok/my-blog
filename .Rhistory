rowTotals <- apply(text_df_lemma_3, 1, sum)
text_df_lemma_3_new <- text_df_lemma_3[rowTotals > 0, ]
df_lda_lemma_3 <- LDA(text_df_lemma_3_new,
k = 6,
control = list(seed = 1234))
df_lda_lemma_3
df_lda_lemma_3_tidy <- tidy(df_lda_lemma_3)
df_lda_lemma_3_tidy
df_lda_lemma_3_tidy_terms <- df_lda_lemma_3_tidy %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal()
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 130) +
theme_minimal()
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 30) +
theme_minimal()
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area() +
theme_minimal()
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 400) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area() +
theme_minimal()
text_df_lemma_1_tidy_count <- text_df_lemma_1_tidy %>%
group_by(term) %>%
summarise(tot_count = sum(count))
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area() +
theme_minimal()
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 300) +
theme_minimal()
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 250) +
theme_minimal()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal()
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/books.jpg")
knitr::include_graphics("image/mapping_topicModeling.png")
knitr::include_graphics("image/Notation of Topic Modeling.png")
knitr::include_graphics("image/textanalytics_with_r.png")
packages <- c('tidyverse', 'readr', 'skimr', 'tidytext', 'quanteda',
'ggwordcloud', 'lexicon', 'topicmodels')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
df <- read_tsv("C:/Users/Jasper Lok/Documents/2_Data Science/my-blog/_posts/2021-12-02-text-analytics/data/WikiQA.tsv",
quote = "\t")
text_df <- tokens(df$Sentence,
remove_punct = TRUE,
remove_numbers = TRUE,
remove_symbols = TRUE,
remove_separators = TRUE,
split_hyphens = FALSE)
text_df <- text_df %>%
tokens_tolower()
text_df <- text_df %>%
tokens_remove(stopwords(language = "en", source = "smart"), padding = FALSE)
text_df <- text_df %>%
tokens_replace(pattern = c("\\d\\w*"), replacement = c(""), valuetype = "regex")
text_df <- text_df %>%
tokens_replace(pattern = c("\\-"), replacement = c(""), valuetype = "regex")
text_df <- text_df %>%
tokens_replace(pattern = c("united st", "u.s"),
replacement = c("united state", "united state"),
valuetype = "fixed") %>%
tokens()
text_df_lemma <- text_df %>%
tokens_replace(pattern = lexicon::hash_lemmas$token,
replacement = lexicon::hash_lemmas$lemma)
text_df_lemma_1 <- text_df_lemma %>%
dfm()
text_df_lemma_1 <- text_df_lemma_1  %>%
dfm_trim(min_termfreq = 10)
topfeatures(text_df_lemma_1, 20)
text_df_lemma_1_tidy <- tidy(text_df_lemma_1)
text_df_lemma_1_tidy_count <- text_df_lemma_1_tidy %>%
group_by(term) %>%
summarise(tot_count = sum(count))
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 500) +
theme_minimal()
text_df_lemma_3 <- text_df_lemma %>%
tokens_ngrams(n = 2:3, concatenator = " ") %>%
dfm()
topfeatures(text_df_lemma_3, 20)
text_df_lemma_3 <- text_df_lemma_3 %>%
dfm_trim(min_termfreq = 30,
max_termfreq = 1000,
termfreq_type = "count")
text_df_lemma_3_tidy <- tidy(text_df_lemma_3)
text_df_lemma_3_tidy_count <- text_df_lemma_3_tidy %>%
group_by(term) %>%
summarise(tot_count = sum(count))
text_df_lemma_3_tidy_count %>%
filter(tot_count >= 45) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 14) +
theme_minimal()
rowTotals <- apply(text_df_lemma_3, 1, sum)
text_df_lemma_3_new <- text_df_lemma_3[rowTotals > 0, ]
df_lda_lemma_3 <- LDA(text_df_lemma_3_new,
k = 6,
control = list(seed = 1234))
df_lda_lemma_3
df_lda_lemma_3_tidy <- tidy(df_lda_lemma_3)
df_lda_lemma_3_tidy
df_lda_lemma_3_tidy_terms <- df_lda_lemma_3_tidy %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal()
knitr::include_graphics("image/reading.jpg")
df_lda_lemma_3@beta
df_lda_lemma_3@alpha
temp_file()
tempfile()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme(text = element_text(size = 20)) +
theme_minimal()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme(text = element_text(size = 20)) +
theme_minimal()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme(text = element_text(size = 30)) +
theme_minimal()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
#  theme() +
theme_minimal(text = element_text(size = 30))
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme(text = element_text(size = 30))# +
#  theme_minimal()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme(text = element_text(size = 20))# +
#  theme_minimal()
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal() +
theme(text = element_text(size = 20))
knitr::include_graphics("image/lda_results.png")
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal() +
theme(text = element_text(size = 20))
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal() +
theme(text = element_text(size = 20))
df_lda_lemma_3 <- LDA(text_df_lemma_3_new,
k = 5,
control = list(seed = 0,
nstart = 1))
df_lda_lemma_3
df_lda_lemma_3@alpha
df_lda_lemma_3_tidy <- tidy(df_lda_lemma_3)
df_lda_lemma_3_tidy
df_lda_lemma_3_tidy_terms <- df_lda_lemma_3_tidy %>%
group_by(topic) %>%
slice_max(beta, n = 10) %>%
ungroup() %>%
arrange(topic, -beta)
df_lda_lemma_3_tidy_terms %>%
mutate(term = reorder_within(term, beta, topic)) %>%
ggplot(aes(beta, term, fill = factor(topic))) +
geom_col(show.legend = FALSE) +
facet_wrap(~topic, scales = "free") +
scale_y_reordered() +
theme_minimal() +
theme(text = element_text(size = 20))
knitr::include_graphics("image/lda_results.png")
knitr::include_graphics("image/reading.jpg")
knitr::include_graphics("image/lda_results.png")
text_df_lemma_1_tidy_count %>%
filter(tot_count >= 500) %>%
ggplot(aes(label = term, size = tot_count, color = tot_count)) +
geom_text_wordcloud_area(shape  = "square") +
scale_size_area(max_size = 500) +
theme_minimal()
# As the topics are being randomized, hence screen shot the results
knitr::include_graphics("image/lda_results.png")
# As the topics are being randomized, hence screen shot the results
knitr::include_graphics("image/lda_results.png")
df_lda_lemma_3_tidy <- tidy(df_lda_lemma_3)
df_lda_lemma_3_tidy
df_lda_lemma_3_tidy <- tidy(df_lda_lemma_3)
df_lda_lemma_3_tidy
knitr::include_graphics("image/question mark.jpg")
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/nice car.jpg")
knitr::include_graphics("image/tiles.jpg")
knitr::include_graphics("image/journey.jpg")
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/end.jpg")
df
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df
exp(-0.007431)
exp(-0.01745)
sessionInfo()
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
sessionInfo()
stats::glm()
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() #%>%
df_1 <- df %>%
select(-c(year, drv.age, veh.age))
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df_1 <- df %>%
select(-c(year, drv.age, veh.age))
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() #%>%
#  bake(df_1)
View(df_recoded)
df_recoded
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() %>%
bake(df_1)
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "kableExtra")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="90%")
library(captioner)
knitr::include_graphics("image/tiles.jpg")
knitr::include_graphics("image/journey.jpg")
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::include_graphics("image/nice car.jpg")
df <- read_csv("data/sim-modeling-dataset.csv",
col_types = list(yrs.lic = col_character()))
df_num <- df %>%
select_if(is.numeric)
corrplot(cor(df_num, use="pairwise.complete.obs"),
method = "number",
type = "upper",
tl.cex = 0.65,
number.cex = 0.65,
diag = FALSE)
df_1 <- df %>%
select(-c(year, drv.age, veh.age))
df_recoded <- df_1 %>%
recipe(clm.count ~ .) %>%
step_dummy(all_nominal_predictors(), one_hot = TRUE) %>%
prep() %>%
bake(df_1)
df_split <- initial_split(df_recoded, prop = 0.6, strata = clm.count)
df_train <- training(df_split)
df_test <- testing(df_split)
# predictors need to be in matrix format
x <- df_train %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
y <- df_train$clm.count
newx <- df_test %>%
select(-c(clm.count, exposure)) %>%
data.matrix()
glmnet_model <- glmnet(x,
y,
family = "poisson",
offset = df_train$exposure)
glmnet_model %>% tidy()
coef(glmnet_model)
alpha_list <- c(0, 0.1, 0.5, 1)
for (i in alpha_list){
cv_glmnet <- cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
print(cv_glmnet)
}
coef(cv_glmnet, s = "lambda.min")
ggplot(df, aes(x = factor(clm.count), y = log(height))) +
geom_violin(draw_quantiles = c(0.5))
ggplot(df, aes(prior.claims)) +
geom_histogram(aes(group = clm.count, fill = clm.count, alpha = 0.15)) #+
#facet_wrap(~clm.count)
cv_glmnet_tidy <- tidy(cv_glmnet)
cv_glmnet_tidy
glance(glmnet_model)
glmnet_predict <- predict(glmnet_model,
type = "response",
newx = newx,
newoffset = log(df_test$exposure))
cv_predict_glmnet <- predict(cv_glmnet, newx = newx, newoffset = log(df_test$exposure), type = "response", s = "lambda.min")
cv_predict_glmnet_tf <- cv_predict_glmnet %>%
as_tibble() %>%
setNames(c("prediction")) %>%
bind_cols(df_test)
cv_predict_glmnet_tf
glance(cv_glmnet)
knitr::include_graphics("image/end.jpg")
coef(glmnet_model, s = "lambda.min")
alpha_list <- c(0, 0.1, 0.5, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(get(glue("cv_glmnet_", i)))
}
packages <- c('tidyverse', 'readr', 'tidymodels', 'corrplot', 'glmnet', 'glue')
for(p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
alpha_list <- c(0, 0.1, 0.5, 1)
for (i in alpha_list){
assign(glue("cv_glmnet_", i), cv.glmnet(x,
y,
family = "poisson",
intercept = FALSE,
type.measure = "deviance",
alpha = i,
nfolds = 20,
offset = log(df_train$exposure))
)
print(get(glue("cv_glmnet_", i)))
}
