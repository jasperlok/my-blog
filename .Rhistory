mutate(total = Claim_No + Claim_Yes,
Claim_perc = Claim_Yes / total * 100)
ggplot(df, aes(x = `Product Name`, fill = Claim)) +
geom_bar(position = "fill") +
theme(axis.text.x = element_text(angle = 90)) +
labs(title = "Claim Proportion by Product Name")
df_prod <- df %>%
group_by(`Product Name`) %>%
summarise(count = n(),
claim_ind = sum(Claim == "Yes")) %>%
mutate(claim_perc = claim_ind/count) %>%
arrange(desc(count)) %>%
mutate(claim_cum_perc = cumsum(count)/sum(count),
product_name_recoded = case_when(claim_cum_perc > 0.9 ~ "Others",
TRUE ~ as.character(`Product Name`))) %>%
select(-c("claim_perc", "claim_cum_perc", "claim_ind", "count")) %>%
ungroup()
df <- df %>%
left_join(df_prod, by = c("Product Name" = "Product Name"))
df %>%
filter(Duration < 1000) %>%
ggplot(aes(product_name_recoded, fill = Claim)) +
geom_bar(position = "fill") +
theme(axis.text.x = element_text(angle = 90)) +
labs(title = "Claim Proportion of Product Name Recoded")
duration_mean <- df %>%
summarise(duration_mean = mean(Duration))
ggplot(df, aes(Duration)) +
geom_density() +
geom_vline(data = duration_mean, aes(xintercept = duration_mean), linetype="dashed", size=0.5) +
annotate("text", x = 800, y = 0.025, label = paste0("Mean of Duration: ", round(duration_mean$duration_mean, 2))) +
labs(title = "Density of Duration")
duration_mean_claim <- df %>%
filter(Duration < 1000, Claim == "Yes") %>%
summarise(mean_dur = mean(Duration),
mean_dur_log = log(mean_dur + 1))
duration_mean_Noclaim <- df %>%
filter(Duration < 1000, Claim == "No") %>%
summarise(mean_dur = mean(Duration),
mean_dur_log = log(mean_dur + 1))
df %>%
filter(Duration < 1000) %>%
ggplot(aes(x = log(Duration + 1), color = Claim)) +
geom_density(alpha = 0.2) +
geom_vline(data = duration_mean_claim, aes(xintercept = mean_dur_log), linetype="dashed", size=0.5) +
annotate("text", x = 5.65, y = 0.32, label = "Average Duration - ") +
annotate("text", x = 5.65, y = 0.3, label = "Claim Policies") +
geom_vline(data = duration_mean_Noclaim, aes(xintercept = mean_dur_log), linetype="solid", size=0.5) +
annotate("text", x = 3, y = 0.03, label = "Average Duration - ") +
annotate("text", x = 3, y = 0.01, label = "No Claim Policies") +
labs(title = "Density of Duration between Claim and No Claim Policies")
netSales_mean_claim <- df %>%
filter(Claim == "Yes",
`Net Sales` > 0) %>%
summarise(netSales_mean_claim = mean(`Net Sales`))
netSales_mean_Noclaim <- df %>%
filter(Claim == "No",
`Net Sales` > 0) %>%
summarise(netSales_mean_Noclaim = mean(`Net Sales`))
df %>%
filter(`Net Sales` > 0) %>%
ggplot(aes(`Net Sales`, color = Claim)) +
geom_density() +
geom_vline(data = netSales_mean_claim, aes(xintercept = netSales_mean_claim), linetype="dashed", size=0.5) +
annotate("text", x = 240, y = 0.03, label = "Average Sales - Claim Policies") +
geom_vline(data = netSales_mean_Noclaim, aes(xintercept = netSales_mean_Noclaim), linetype="solid", size=0.5) +
annotate("text", x = 200, y = 0.02, label = "Average Sales - No Claim Policies") +
labs(title = "Density of Sales between Claim and No Claim Policies")
comm_mean_claim <- df %>%
filter(Claim == "Yes") %>%
summarise(comm_mean_claim = mean(Commission))
comm_mean_Noclaim <- df %>%
filter(Claim == "No") %>%
summarise(comm_mean_Noclaim = mean(Commission))
df %>%
ggplot(aes(Commission, color = Claim)) +
geom_density() +
geom_vline(data = comm_mean_claim, aes(xintercept = comm_mean_claim), linetype="dashed", size=0.5) +
annotate("text", x = 80, y = 0.1, label = "Average Commission - Claim Policies") +
geom_vline(data = comm_mean_Noclaim, aes(xintercept = comm_mean_Noclaim), linetype="solid", size=0.5) +
annotate("text", x = 100, y = 0.15, label = "Average Commission - No Claim Policies") +
labs(title = "Density of Commission between Claim and No Claim Policies")
age_mean_claim <- df %>%
filter(Claim == "Yes") %>%
summarise(age_mean_claim = mean(Age))
age_mean_Noclaim <- df %>%
filter(Claim == "No") %>%
summarise(age_mean_Noclaim = mean(Age))
df %>%
ggplot(aes(Age, color = Claim)) +
geom_density() +
geom_vline(data = age_mean_claim, aes(xintercept = age_mean_claim), linetype="dashed", size=0.5) +
annotate("text", x = 20, y = 0.1, label = "Average Age - ") +
annotate("text", x = 20, y = 0.088, label = "Claim Policies") +
geom_vline(data = age_mean_Noclaim, aes(xintercept = age_mean_Noclaim), linetype="solid", size=0.5) +
annotate("text", x = 68, y = 0.15, label = "Average Age - No Claim Policies") +
labs(title = "Density of Age between Claim and No Claim Policies")
View(df)
df %>%
filter(Age > 100)
df %>%
filter(Age > 100) %>%
tally()
install.packages("stacks")
install.packages("ranger")
install.packages("xgboost")
install.packages("earth")
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "tidymodels", "stacks")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="70%")
library(captioner)
knitr::include_graphics("image/cup_stack.jpg")
knitr::include_graphics("image/Graph on Different Machine Learning.png")
knitr::include_graphics("image/model stacking steps.png")
knitr::include_graphics("image/bricks stack.jpg")
knitr::include_graphics("image/logo_stacks.png")
knitr::include_graphics("image/hooray.jpg")
packages <- c("tidyverse", "tidymodels", "stacks")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
# Define the random seeds for reproducibility
set.seed(1234)
# Proportion between training and testing dataset
prop_train_test <- 0.6
# Define the model performance metrics we would like to output later
model_metrics <- metric_set(rmse, rsq)
# The number of grid to be used in the analysis later
grid_num <- 5
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
library('doParallel')
registerDoParallel() #as many physical cores as available.
df <- read_csv("data/data_eda_actLoss_3.csv") %>%
dplyr::select(-c(ClaimNumber,
num_week_paid_ult,
InitialIncurredClaimCost,
UltimateIncurredClaimCost)) %>%
dplyr::select(-starts_with(c("acc", "report"))) %>%
filter(Gender != "U") %>%
drop_na() %>%
sample_frac(0.1)
# Split dataset
df_split <- initial_split(df,
prop = prop_train_test,
strata = init_ult_diff)
df_train <- training(df_split)
df_test <- testing(df_split)
# Cross validation
df_folds <- vfold_cv(df_train, strata = init_ult_diff)
gen_recipe <- recipe(init_ult_diff ~ ., data = df_train) %>%
update_role(c(DateTimeOfAccident, DateReported, ClaimDescription), new_role = "id") %>% # update the roles of original date variables to "id"
prep()
ranger_spec <-
rand_forest() %>%
set_mode("regression") %>%
set_engine("ranger", importance = "impurity")
ranger_workflow <-
workflow() %>%
add_recipe(gen_recipe) %>%
add_model(ranger_spec)
set.seed(51107)
ranger_tune <-
tune_grid(ranger_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
xgboost_recipe <- gen_recipe %>%
step_dummy(all_nominal())
xgboost_spec <-
boost_tree() %>%
set_mode("regression") %>%
set_engine("xgboost")
xgboost_workflow <-
workflow() %>%
add_recipe(xgboost_recipe) %>%
add_model(xgboost_spec)
set.seed(12071)
xgboost_tune <-
tune_grid(xgboost_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
earth_recipe <- gen_recipe %>%
step_novel(all_nominal(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_zv(all_predictors())
earth_spec <-
mars() %>%
set_mode("regression") %>%
set_engine("earth")
earth_workflow <-
workflow() %>%
add_recipe(earth_recipe) %>%
add_model(earth_spec)
earth_grid <- tidyr::crossing(num_terms = 2 * (1:6), prod_degree = 1:2)
earth_tune <-
tune_grid(earth_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
stack_model <-
stacks() %>%
add_candidates(ranger_tune) %>%
add_candidates(xgboost_tune) %>%
add_candidates(earth_tune)
??extract_spec_parsnip
install.packages("workflows")
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "tidymodels", "stacks")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="70%")
library(captioner)
knitr::include_graphics("image/cup_stack.jpg")
knitr::include_graphics("image/Graph on Different Machine Learning.png")
knitr::include_graphics("image/model stacking steps.png")
knitr::include_graphics("image/bricks stack.jpg")
knitr::include_graphics("image/logo_stacks.png")
knitr::include_graphics("image/hooray.jpg")
packages <- c("tidyverse", "tidymodels", "stacks")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
# Define the random seeds for reproducibility
set.seed(1234)
# Proportion between training and testing dataset
prop_train_test <- 0.6
# Define the model performance metrics we would like to output later
model_metrics <- metric_set(rmse, rsq)
# The number of grid to be used in the analysis later
grid_num <- 5
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
library('doParallel')
registerDoParallel() #as many physical cores as available.
df <- read_csv("data/data_eda_actLoss_3.csv") %>%
dplyr::select(-c(ClaimNumber,
num_week_paid_ult,
InitialIncurredClaimCost,
UltimateIncurredClaimCost)) %>%
dplyr::select(-starts_with(c("acc", "report"))) %>%
filter(Gender != "U") %>%
drop_na() %>%
sample_frac(0.1)
# Split dataset
df_split <- initial_split(df,
prop = prop_train_test,
strata = init_ult_diff)
df_train <- training(df_split)
df_test <- testing(df_split)
# Cross validation
df_folds <- vfold_cv(df_train, strata = init_ult_diff)
gen_recipe <- recipe(init_ult_diff ~ ., data = df_train) %>%
update_role(c(DateTimeOfAccident, DateReported, ClaimDescription), new_role = "id") %>% # update the roles of original date variables to "id"
prep()
ranger_spec <-
rand_forest(mtry = tune()) %>%
set_mode("regression") %>%
set_engine("ranger", importance = "impurity")
ranger_workflow <-
workflow() %>%
add_recipe(gen_recipe) %>%
add_model(ranger_spec)
set.seed(51107)
ranger_tune <-
tune_grid(ranger_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
xgboost_recipe <- gen_recipe %>%
step_dummy(all_nominal())
xgboost_spec <-
boost_tree(mtry = tune()) %>%
set_mode("regression") %>%
set_engine("xgboost")
xgboost_workflow <-
workflow() %>%
add_recipe(xgboost_recipe) %>%
add_model(xgboost_spec)
set.seed(12071)
xgboost_tune <-
tune_grid(xgboost_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
earth_recipe <- gen_recipe %>%
step_novel(all_nominal(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_zv(all_predictors())
earth_spec <-
mars(prod_degree = tune()) %>%
set_mode("regression") %>%
set_engine("earth")
earth_workflow <-
workflow() %>%
add_recipe(earth_recipe) %>%
add_model(earth_spec)
earth_grid <- tidyr::crossing(num_terms = 2 * (1:6), prod_degree = 1:2)
earth_tune <-
tune_grid(earth_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
stack_model <-
stacks() %>%
add_candidates(ranger_tune) %>%
add_candidates(xgboost_tune) %>%
add_candidates(earth_tune)
install.packages("workflows")
options(htmltools.dir.version = FALSE)
packages <- c("captioner", "knitr", "tidyverse", "tidymodels", "stacks")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
knitr::opts_chunk$set(fig.retina = 3,
echo = TRUE,
eval = TRUE,
message = FALSE,
warning = FALSE,
out.width="70%")
library(captioner)
knitr::include_graphics("image/cup_stack.jpg")
knitr::include_graphics("image/Graph on Different Machine Learning.png")
knitr::include_graphics("image/model stacking steps.png")
knitr::include_graphics("image/bricks stack.jpg")
knitr::include_graphics("image/logo_stacks.png")
knitr::include_graphics("image/hooray.jpg")
packages <- c("tidyverse", "tidymodels", "stacks")
for (p in packages){
if(!require (p, character.only = T)){
install.packages(p)
}
library(p, character.only = T)
}
# Define the random seeds for reproducibility
set.seed(1234)
# Proportion between training and testing dataset
prop_train_test <- 0.6
# Define the model performance metrics we would like to output later
model_metrics <- metric_set(rmse, rsq)
# The number of grid to be used in the analysis later
grid_num <- 5
ctrl_grid <- control_stack_grid()
ctrl_res <- control_stack_resamples()
library('doParallel')
registerDoParallel() #as many physical cores as available.
df <- read_csv("data/data_eda_actLoss_3.csv") %>%
dplyr::select(-c(ClaimNumber,
num_week_paid_ult,
InitialIncurredClaimCost,
UltimateIncurredClaimCost)) %>%
dplyr::select(-starts_with(c("acc", "report"))) %>%
filter(Gender != "U") %>%
drop_na() %>%
sample_frac(0.1)
# Split dataset
df_split <- initial_split(df,
prop = prop_train_test,
strata = init_ult_diff)
df_train <- training(df_split)
df_test <- testing(df_split)
# Cross validation
df_folds <- vfold_cv(df_train, strata = init_ult_diff)
gen_recipe <- recipe(init_ult_diff ~ ., data = df_train) %>%
update_role(c(DateTimeOfAccident, DateReported, ClaimDescription), new_role = "id") %>% # update the roles of original date variables to "id"
prep()
ranger_spec <-
rand_forest(mtry = tune()) %>%
set_mode("regression") %>%
set_engine("ranger", importance = "impurity")
ranger_workflow <-
workflow() %>%
add_recipe(gen_recipe) %>%
add_model(ranger_spec)
set.seed(51107)
ranger_tune <-
tune_grid(ranger_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
xgboost_recipe <- gen_recipe %>%
step_dummy(all_nominal())
xgboost_spec <-
boost_tree(mtry = tune()) %>%
set_mode("regression") %>%
set_engine("xgboost")
xgboost_workflow <-
workflow() %>%
add_recipe(xgboost_recipe) %>%
add_model(xgboost_spec)
set.seed(12071)
xgboost_tune <-
tune_grid(xgboost_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
earth_recipe <- gen_recipe %>%
step_novel(all_nominal(), -all_outcomes()) %>%
step_dummy(all_nominal(), -all_outcomes()) %>%
step_zv(all_predictors())
earth_spec <-
mars(prod_degree = tune()) %>%
set_mode("regression") %>%
set_engine("earth")
earth_workflow <-
workflow() %>%
add_recipe(earth_recipe) %>%
add_model(earth_spec)
earth_grid <- tidyr::crossing(num_terms = 2 * (1:6), prod_degree = 1:2)
earth_tune <-
tune_grid(earth_workflow,
resamples = df_folds,
grid = grid_num,
control = ctrl_grid)
stack_model <-
stacks() %>%
add_candidates(ranger_tune) %>%
add_candidates(xgboost_tune) %>%
add_candidates(earth_tune)
stack_model_pred <-
stack_model %>%
blend_predictions()
stack_model_pred
autoplot(stack_model_pred, type = "weights")
stack_model_fit <- stack_model_pred %>%
fit_members()
# Finalize the workflow by selecting the best parameters
ranger_fit <- ranger_workflow %>%
finalize_workflow(select_best(ranger_tune)) %>%
last_fit(df_split)
# Extract the predictions from the fitted model
ranger_pred <- ranger_fit %>%
collect_predictions()
# Calculate the model performance metric
ranger_metric <- model_metrics(ranger_pred,
truth = init_ult_diff,
estimate = .pred) %>%
mutate(model = "ranger") %>%
pivot_wider(names_from = .metric,
values_from = .estimate)
# Finalize the workflow by selecting the best parameters
xgboost_fit <- xgboost_workflow %>%
finalize_workflow(select_best(xgboost_tune)) %>%
last_fit(df_split)
# Extract the predictions from the fitted model
xgboost_pred <- xgboost_fit %>%
collect_predictions()
# Calculate the model performance metric
xgboost_metric <- model_metrics(xgboost_pred,
truth = init_ult_diff,
estimate = .pred) %>%
mutate(model = "xgboost") %>%
pivot_wider(names_from = .metric,
values_from = .estimate)
# Finalize the workflow by selecting the best parameters
earth_fit <- earth_workflow %>%
finalize_workflow(select_best(earth_tune)) %>%
last_fit(df_split)
# Extract the predictions from the fitted model
earth_pred <- earth_fit %>%
collect_predictions()
# Calculate the model performance metric
earth_metric <- model_metrics(earth_pred,
truth = init_ult_diff,
estimate = .pred) %>%
mutate(model = "earth") %>%
pivot_wider(names_from = .metric,
values_from = .estimate)
stack_metric <- predict(stack_model_fit, df_test) %>%
bind_cols(init_ult_diff = df_test$init_ult_diff) %>%
model_metrics(truth = init_ult_diff, estimate = .pred) %>%
mutate(model = "stack") %>%
pivot_wider(names_from = .metric,
values_from = .estimate)
tibble() %>%
bind_rows(stack_metric) %>%
bind_rows(ranger_metric) %>%
bind_rows(xgboost_metric) %>%
bind_rows(earth_metric)
library.packages("ggstatplot")
install.packages("ggstatplot")
install.packages("ggstatsplot")
